{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción\n",
    "\n",
    "Este script hace la ejecución de Extracción, Procesamiento y Carga (ETL) de los archivos del sitio [Quién es Quién en los precios](https://datos.profeco.gob.mx/datos_abiertos/qqp.php).\n",
    "\n",
    "Una vez procesados estarán disponibles para la parte A y B del trabajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: awswrangler in c:\\users\\javier_castillo.ltsfe-jcm\\.conda\\envs\\arquitectura\\lib\\site-packages (3.7.1)\n",
      "Requirement already satisfied: boto3<2.0.0,>=1.20.32 in c:\\users\\javier_castillo.ltsfe-jcm\\.conda\\envs\\arquitectura\\lib\\site-packages (from awswrangler) (1.34.69)\n",
      "Requirement already satisfied: botocore<2.0.0,>=1.23.32 in c:\\users\\javier_castillo.ltsfe-jcm\\.conda\\envs\\arquitectura\\lib\\site-packages (from awswrangler) (1.34.69)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18 in c:\\users\\javier_castillo.ltsfe-jcm\\.conda\\envs\\arquitectura\\lib\\site-packages (from awswrangler) (1.26.4)\n",
      "Requirement already satisfied: packaging<24.0,>=21.1 in c:\\users\\javier_castillo.ltsfe-jcm\\.conda\\envs\\arquitectura\\lib\\site-packages (from awswrangler) (23.2)\n",
      "Requirement already satisfied: pandas<3.0.0,>=1.2.0 in c:\\users\\javier_castillo.ltsfe-jcm\\.conda\\envs\\arquitectura\\lib\\site-packages (from awswrangler) (2.2.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\javier_castillo.ltsfe-jcm\\.conda\\envs\\arquitectura\\lib\\site-packages (from awswrangler) (15.0.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.4.0 in c:\\users\\javier_castillo.ltsfe-jcm\\.conda\\envs\\arquitectura\\lib\\site-packages (from awswrangler) (4.10.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\javier_castillo.ltsfe-jcm\\.conda\\envs\\arquitectura\\lib\\site-packages (from boto3<2.0.0,>=1.20.32->awswrangler) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in c:\\users\\javier_castillo.ltsfe-jcm\\.conda\\envs\\arquitectura\\lib\\site-packages (from boto3<2.0.0,>=1.20.32->awswrangler) (0.10.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\javier_castillo.ltsfe-jcm\\.conda\\envs\\arquitectura\\lib\\site-packages (from botocore<2.0.0,>=1.23.32->awswrangler) (2.9.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in c:\\users\\javier_castillo.ltsfe-jcm\\.conda\\envs\\arquitectura\\lib\\site-packages (from botocore<2.0.0,>=1.23.32->awswrangler) (2.2.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\javier_castillo.ltsfe-jcm\\.conda\\envs\\arquitectura\\lib\\site-packages (from pandas<3.0.0,>=1.2.0->awswrangler) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\javier_castillo.ltsfe-jcm\\.conda\\envs\\arquitectura\\lib\\site-packages (from pandas<3.0.0,>=1.2.0->awswrangler) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\javier_castillo.ltsfe-jcm\\.conda\\envs\\arquitectura\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<2.0.0,>=1.23.32->awswrangler) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: boto3 in c:\\users\\javier_castillo.ltsfe-jcm\\.conda\\envs\\arquitectura\\lib\\site-packages (1.34.69)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.69 in c:\\users\\javier_castillo.ltsfe-jcm\\.conda\\envs\\arquitectura\\lib\\site-packages (from boto3) (1.34.69)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\javier_castillo.ltsfe-jcm\\.conda\\envs\\arquitectura\\lib\\site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in c:\\users\\javier_castillo.ltsfe-jcm\\.conda\\envs\\arquitectura\\lib\\site-packages (from boto3) (0.10.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\javier_castillo.ltsfe-jcm\\.conda\\envs\\arquitectura\\lib\\site-packages (from botocore<1.35.0,>=1.34.69->boto3) (2.9.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in c:\\users\\javier_castillo.ltsfe-jcm\\.conda\\envs\\arquitectura\\lib\\site-packages (from botocore<1.35.0,>=1.34.69->boto3) (2.2.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\javier_castillo.ltsfe-jcm\\.conda\\envs\\arquitectura\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.69->boto3) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: rarfile in c:\\users\\javier_castillo.ltsfe-jcm\\.conda\\envs\\arquitectura\\lib\\site-packages (4.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: selenium in c:\\users\\javier_castillo.ltsfe-jcm\\.conda\\envs\\arquitectura\\lib\\site-packages (4.19.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\javier_castillo.ltsfe-jcm\\.conda\\envs\\arquitectura\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.1)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\javier_castillo.ltsfe-jcm\\.conda\\envs\\arquitectura\\lib\\site-packages (from selenium) (0.25.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\javier_castillo.ltsfe-jcm\\.conda\\envs\\arquitectura\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\javier_castillo.ltsfe-jcm\\.conda\\envs\\arquitectura\\lib\\site-packages (from selenium) (2024.2.2)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\javier_castillo.ltsfe-jcm\\.conda\\envs\\arquitectura\\lib\\site-packages (from selenium) (4.10.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\javier_castillo.ltsfe-jcm\\.conda\\envs\\arquitectura\\lib\\site-packages (from trio~=0.17->selenium) (23.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\javier_castillo.ltsfe-jcm\\.conda\\envs\\arquitectura\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\javier_castillo.ltsfe-jcm\\.conda\\envs\\arquitectura\\lib\\site-packages (from trio~=0.17->selenium) (3.6)\n",
      "Requirement already satisfied: outcome in c:\\users\\javier_castillo.ltsfe-jcm\\.conda\\envs\\arquitectura\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\javier_castillo.ltsfe-jcm\\.conda\\envs\\arquitectura\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\javier_castillo.ltsfe-jcm\\.conda\\envs\\arquitectura\\lib\\site-packages (from trio~=0.17->selenium) (1.16.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\javier_castillo.ltsfe-jcm\\.conda\\envs\\arquitectura\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\javier_castillo.ltsfe-jcm\\.conda\\envs\\arquitectura\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\javier_castillo.ltsfe-jcm\\.conda\\envs\\arquitectura\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\javier_castillo.ltsfe-jcm\\.conda\\envs\\arquitectura\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tqdm in c:\\users\\javier_castillo.ltsfe-jcm\\.conda\\envs\\arquitectura\\lib\\site-packages (4.66.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\javier_castillo.ltsfe-jcm\\.conda\\envs\\arquitectura\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: unidecode in c:\\users\\javier_castillo.ltsfe-jcm\\.conda\\envs\\arquitectura\\lib\\site-packages (1.3.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Library installation of resources not in conda environment \"arquitectura\"\n",
    "%pip install awswrangler\n",
    "%pip install boto3\n",
    "%pip install rarfile\n",
    "%pip install selenium\n",
    "%pip install tqdm\n",
    "%pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import awswrangler as wr\n",
    "import boto3\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import rarfile\n",
    "import re\n",
    "import requests\n",
    "import seaborn as sns\n",
    "import subprocess\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga y Preparacion de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descargar los archivos desde el sitio [Quién es Quién en los precios](https://datos.profeco.gob.mx/datos_abiertos/qqp.php) y descomprimirlos en la carpeta `data/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved: data\\Base de Datos Histórica Quién es Quién en los Precios 2024.rar\n",
      "File saved: data\\Base de Datos Histórica Quién es Quién en los Precios 2023.rar\n",
      "File saved: data\\Base de Datos Histórica Quién es Quién en los Precios 2022.rar\n",
      "File saved: data\\Base de Datos Histórica Quién es Quién en los Precios 2021.rar\n",
      "File saved: data\\Base de Datos Histórica Quién es Quién en los Precios 2020.rar\n",
      "File saved: data\\Base de Datos Histórica Quién es Quién en los Precios 2019.rar\n",
      "File saved: data\\Base de Datos Histórica Quién es Quién en los Precios 2018.rar\n",
      "File saved: data\\Base de Datos Histórica Quién es Quién en los Precios 2017.rar\n",
      "File saved: data\\Base de Datos Histórica Quién es Quién en los Precios 2016.rar\n",
      "File saved: data\\Base de Datos Histórica Quién es Quién en los Precios 2015.rar\n"
     ]
    }
   ],
   "source": [
    "# Function to ensure the data directory exists\n",
    "def ensure_dir(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "# Base URL for making complete links\n",
    "base_url = \"https://datos.profeco.gob.mx/datos_abiertos/\"\n",
    "\n",
    "# URL of the page to scrape\n",
    "url = \"https://datos.profeco.gob.mx/datos_abiertos/qqp.php\"\n",
    "\n",
    "# Ensure the data directory exists\n",
    "ensure_dir('data')\n",
    "\n",
    "# Send HTTP GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find all <li> tags that contain <a> tags within them\n",
    "    links = soup.find_all('li')\n",
    "    file_links = []\n",
    "    \n",
    "    for link in links:\n",
    "        a_tag = link.find('a', href=True)\n",
    "        if a_tag and 'file.php?t=' in a_tag['href']:\n",
    "            # Create the complete URL for the link\n",
    "            complete_url = base_url + a_tag['href']\n",
    "            file_links.append((complete_url, a_tag.text))\n",
    "\n",
    "    # Visit each link and download the file\n",
    "    for file_link, name in file_links:\n",
    "        try:\n",
    "            # Make the request\n",
    "            response = requests.get(file_link)\n",
    "            # Save the content to a file\n",
    "            if response.status_code == 200:\n",
    "                file_path = os.path.join('data', name.replace('/', '_') + '.rar')  # Replace slashes just in case\n",
    "                with open(file_path, 'wb') as file:\n",
    "                    file.write(response.content)\n",
    "                print(f\"File saved: {file_path}\")\n",
    "            else:\n",
    "                print(f\"Failed to download the file from {file_link}. Status code: {response.status_code}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while downloading {file_link}: {str(e)}\")\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage. Status code:\", response.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desempacar los archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_rar_files(directory):\n",
    "    # Change this path to your 7-Zip executable if it's not in the PATH\n",
    "    seven_zip_path = \"7z\"\n",
    "    \n",
    "    # List all files in the given directory\n",
    "    files = os.listdir(directory)\n",
    "    \n",
    "    # Filter for .rar files\n",
    "    rar_files = [file for file in files if file.endswith('.rar')]\n",
    "    \n",
    "    # Extract each .rar file\n",
    "    for rar in rar_files:\n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(directory, rar)\n",
    "        # Command to extract the files\n",
    "        command = [seven_zip_path, 'x', file_path, '-o' + directory]\n",
    "        # Run the command\n",
    "        subprocess.run(command, check=True)\n",
    "\n",
    "# Replace 'data' with your directory path if different\n",
    "unpack_rar_files('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esquema de los archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the expected columns based on the provided schema\n",
    "expected_columns = [\n",
    "    'producto', 'presentacion', 'marca', 'categoria', 'catalogo', 'precio',\n",
    "    'fecha_registro', 'cadena_comercial', 'giro', 'nombre_comercial', 'direccion',\n",
    "    'estado', 'municipio', 'latitud', 'longitud'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directorio que contiene los archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the CSV files\n",
    "data_dir = 'data'  # Adjust this path as needed in your local setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encontrar todos los archivos en el directorio \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find all CSV files in directory and subdirectories\n",
    "def find_csv_files(directory):\n",
    "    csv_files = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.csv'):\n",
    "                csv_files.append(os.path.join(root, file))\n",
    "    return csv_files\n",
    "\n",
    "# Get all CSV files\n",
    "csv_files = find_csv_files(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leer todos los archivos para generar uno solo de la categoría indicada (en este caso, \"Material escolar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/450 [00:10<30:34,  4.10s/it]C:\\Users\\Javier_Castillo.LTSFE-JCM\\AppData\\Local\\Temp\\ipykernel_27916\\3876094121.py:39: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_data = pd.concat([all_data, valid_data], ignore_index=True)\n",
      "100%|██████████| 450/450 [49:45<00:00,  6.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total valid rows loaded: 5189153\n",
      "Total invalid rows found: 527494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty DataFrame for valid data and one for errors\n",
    "all_data = pd.DataFrame(columns=['filename'] + expected_columns)\n",
    "errors = pd.DataFrame(columns=['filename', 'error_row'])\n",
    "\n",
    "# Function to clean and transform data\n",
    "def clean_data(data):\n",
    "    # Remove accents\n",
    "    for column in data.columns:\n",
    "        data[column] = data[column].apply(lambda x: unidecode(str(x)) if isinstance(x, str) and pd.notnull(x) else x)\n",
    "    # Convert to lowercase\n",
    "    data = data.apply(lambda x: x.str.lower() if x.dtype == \"object\" else x)\n",
    "    # Change commas to pipes in 'direccion', considering complex rules\n",
    "    data['direccion'] = data['direccion'].apply(lambda x: re.sub(r',(?![^\"]*\"(?:(?:[^\"]*\"){2})*[^\"]*$)', '|', x) if pd.notnull(x) else x)\n",
    "    return data\n",
    "\n",
    "# Read each file and validate rows\n",
    "for file_path in tqdm(csv_files):\n",
    "    try:\n",
    "        # Read the file assuming no headers and using the expected columns\n",
    "        data = pd.read_csv(file_path, header=None, names=expected_columns)\n",
    "\n",
    "        # Filter data for 'categoria' equals 'material escolar'\n",
    "        filtered_data = data[data['categoria'] == 'MATERIAL ESCOLAR']\n",
    "\n",
    "        # Clean and transform data\n",
    "        data = clean_data(data)\n",
    "\n",
    "        # Add filename column to the DataFrame\n",
    "        data['filename'] = os.path.basename(file_path)\n",
    "\n",
    "        # Ensure filename is the first column\n",
    "        data = data[['filename'] + expected_columns]\n",
    "\n",
    "        # Drop rows and columns that are completely NA\n",
    "        valid_data = filtered_data.dropna(how='all').dropna(axis=1, how='all')\n",
    "        \n",
    "        # Concatenate data while checking for non-empty DataFrame to avoid FutureWarning\n",
    "        if not valid_data.empty:\n",
    "            all_data = pd.concat([all_data, valid_data], ignore_index=True)\n",
    "        \n",
    "        # Identify invalid rows and add them to the errors DataFrame\n",
    "        invalid_rows = data[data.isna().any(axis=1)]\n",
    "        if not invalid_rows.empty:\n",
    "            invalid_row_str = invalid_rows[expected_columns].apply(lambda x: ','.join(x.fillna('').map(str)), axis=1)\n",
    "            errors_df = pd.DataFrame({\n",
    "                'filename': os.path.basename(file_path),\n",
    "                'error_row': invalid_row_str\n",
    "            })\n",
    "            errors = pd.concat([errors, errors_df], ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "\n",
    "# Output results\n",
    "print(f\"Total valid rows loaded: {len(all_data)}\")\n",
    "print(f\"Total invalid rows found: {len(errors)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exportar los datos y los errores a la carpeta indicada ya comprimidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export errors df to a compressed csv file using gzip\n",
    "errors.to_csv('./data_clean/errors.csv.gz', index=False, compression='gzip')\n",
    "\n",
    "# Export the cleaned data to a compressed CSV file using gzip\n",
    "all_data.to_csv('./data_clean/all_data.csv.gz', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar los archivos a S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a session using a specific profile\n",
    "session = boto3.Session(profile_name='arquitectura_AWS_ITAM_2024', region_name='us-east-1')\n",
    "\n",
    "# Create an S3 client from this session\n",
    "s3 = session.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths to upload\n",
    "error_file_path = './data_clean/errors.csv.gz'\n",
    "data_file_path = './data_clean/all_data.csv.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bucket name\n",
    "bucket_name = 'mdge-e3-2024'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files uploaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Upload files\n",
    "try:\n",
    "    s3.upload_file(error_file_path, bucket_name, 'errors.csv.gz')\n",
    "    s3.upload_file(data_file_path, bucket_name, 'all_data.csv.gz')\n",
    "    print(\"Files uploaded successfully\")\n",
    "except boto3.exceptions.S3UploadFailedError as e:\n",
    "    print(\"Failed to upload: \", e)\n",
    "except Exception as e:\n",
    "    print(\"An error occurred: \", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan], dtype=object)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list  all distinct values in filename column\n",
    "test = all_data['filename'].unique()\n",
    "\n",
    "test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
