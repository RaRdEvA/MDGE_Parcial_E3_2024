{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10ee7920",
   "metadata": {},
   "source": [
    "- Carga el CSV en Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb179cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create or get a Spark session\n",
    "spark = SparkSession.builder.appName(\"Read Compressed CSV from S3\").getOrCreate()\n",
    "\n",
    "# Define the path to your S3 bucket and compressed CSV files\n",
    "s3_bucket_path = \"s3://mdge-e3-2024/*.csv.gz\"\n",
    "\n",
    "# Read the compressed CSV files into a DataFrame\n",
    "df = spark.read.csv(s3_bucket_path, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa26040e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add \"year\" and \"month\" columns based on \"fecha_registro\"\n",
    "from pyspark.sql import functions as F\n",
    "df = df.withColumn(\"year\", F.year(\"fecha_registro\"))\n",
    "df = df.withColumn(\"month\", F.month(\"fecha_registro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335b512d",
   "metadata": {},
   "source": [
    "- Guarda el CSV como parquet en S3, particionalo por `catalogo`. (Utiliza todos los trucos que consideres)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fcae741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define output directory\n",
    "output_directory = \"s3://mdge-e3-2024/parquet_files_partitioned/\"\n",
    "\n",
    "# Write the DataFrame to Parquet, partitioned by 'categoria', 'year', and 'month'\n",
    "df.write.partitionBy(\"categoria\", \"year\", \"month\").mode('overwrite').parquet(output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b5dac2",
   "metadata": {},
   "source": [
    "- Carga el parquet en Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b90e95a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read the Parquet files into a DataFrame\n",
    "df_parquet = spark.read.parquet(output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f170cbdb",
   "metadata": {},
   "source": [
    "Contesta las siguientes preguntas utilizando PySpark. Realiza el siguiente análisis **(por año)** y sobre todos los catálogos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f21ca22",
   "metadata": {},
   "source": [
    "- ¿Cuántos catálogos diferentes tenemos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04c0ce2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|distinct_catalogs|\n",
      "+-----------------+\n",
      "|               12|\n",
      "+-----------------+"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "# Count distinct catalogs\n",
    "distinct_catalogs = df_parquet.agg(countDistinct(\"catalogo\").alias(\"distinct_catalogs\"))\n",
    "distinct_catalogs.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e634247",
   "metadata": {},
   "source": [
    "- ¿Cuáles son los20 catálogos con más observaciones? Guarda la salida de este query en tu bucket de S3, lo necesitaremos más adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0bd9db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+\n",
      "|           catalogo|   count|\n",
      "+-------------------+--------+\n",
      "|            basicos|72474782|\n",
      "|       medicamentos|29402008|\n",
      "|  electrodomesticos|12276099|\n",
      "| frutas y legumbres| 7571260|\n",
      "|   utiles escolares| 5160328|\n",
      "|           mercados| 3292185|\n",
      "|           juguetes| 2651525|\n",
      "|              pacic| 1079162|\n",
      "|pescados y mariscos|  789438|\n",
      "|          navidenos|  428681|\n",
      "|              tenis|   31626|\n",
      "|        aeropuertos|     581|\n",
      "+-------------------+--------+"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "\n",
    "# Find top 20 catalogs by number of observations\n",
    "top_20_catalogs = df_parquet.groupBy(\"catalogo\").count().orderBy(desc(\"count\")).limit(20)\n",
    "top_20_catalogs.show()\n",
    "\n",
    "# Save the output to S3\n",
    "top_20_catalogs.write.mode('overwrite').parquet(\"s3://mdge-e3-2024/top_20_catalogs/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a77f93",
   "metadata": {},
   "source": [
    "- ¿Tenemos datos de todos los estados del país? De no ser así, ¿cuáles faltan?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ff911c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_states = [\n",
    "    \"aguascalientes\", \"baja california\", \"baja california sur\", \"campeche\", \"chiapas\",\n",
    "    \"chihuahua\", \"ciudad de mexico\", \"distrito federal\", \"coahuila de zaragoza\", \"colima\", \"durango\", \"guanajuato\",\n",
    "    \"guerrero\", \"hidalgo\", \"jalisco\", \"estado de mexico\", \"michoacan de ocampo\", \"morelos\", \"nayarit\",\n",
    "    \"nuevo leon\", \"oaxaca\", \"puebla\", \"queretaro\", \"quintana roo\", \"san luis potosi\",\n",
    "    \"sinaloa\", \"sonora\", \"tabasco\", \"tamaulipas\", \"tlaxcala\", \"veracruz\", \"yucatan\", \"zacatecas\"\n",
    "]\n",
    "\n",
    "# Get distinct states from DataFrame\n",
    "states_in_data = df_parquet.select(\"estado\").distinct().rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "# Find missing states\n",
    "missing_states = [state for state in all_states if state not in states_in_data]\n",
    "print(\"Missing States:\", missing_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b829922",
   "metadata": {},
   "source": [
    "- ¿Cuántas observaciones tenemos por estado?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cffa2217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------+\n",
      "|          estado|   count|\n",
      "+----------------+--------+\n",
      "|      tamaulipas| 3836149|\n",
      "|       zacatecas| 3221774|\n",
      "|      nuevo leon| 5229471|\n",
      "|        campeche| 2611299|\n",
      "| san luis potosi| 2605944|\n",
      "|        veracruz| 4181993|\n",
      "|         morelos| 1509095|\n",
      "|      guanajuato| 4933886|\n",
      "|          sonora| 3511149|\n",
      "|        tlaxcala| 2843154|\n",
      "|         nayarit|  992414|\n",
      "|         sinaloa| 2264742|\n",
      "|          oaxaca| 2244336|\n",
      "|        guerrero| 1858948|\n",
      "|    quintana roo| 4754708|\n",
      "|       queretaro| 3385694|\n",
      "|estado de mexico|17656040|\n",
      "|          puebla| 3514964|\n",
      "|         durango| 2389334|\n",
      "|         jalisco| 6446410|\n",
      "+----------------+--------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "# Count observations by state\n",
    "observations_by_state = df_parquet.groupBy(\"estado\").count()\n",
    "observations_by_state.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c1ac4d",
   "metadata": {},
   "source": [
    "- De cada estado obten: el número de catalogos diferentes por año, ¿ha aumentado el número de catálogos con el tiempo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e48f60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feede54daa27406184a4535e46fa03a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import year\n",
    "\n",
    "# Count distinct catalogs per state per year\n",
    "catalogs_per_state_per_year = df_parquet.groupBy(\"estado\", \"year\").agg(countDistinct(\"catalogo\").alias(\"distinct_catalogs\"))\n",
    "catalogs_per_state_per_year.show()\n",
    "\n",
    "# To check if the number of catalogs has increased over the years, we will order the results\n",
    "trend_catalogs = catalogs_per_state_per_year.orderBy(\"estado\", \"year\")\n",
    "trend_catalogs.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141e0ff1",
   "metadata": {},
   "source": [
    "Utilizando Spark contesta las siguientes preguntas a partir **del catálogo que\n",
    "le tocó a tu equipo**. Recuerda trabajar en el archivo con los datos particionados\n",
    "de otra manera tus queries van a tardar mucho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1b8b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Material Escolar Analysis\").getOrCreate()\n",
    "\n",
    "# Read data from the specific category partition\n",
    "df_cat = spark.read.parquet(\"s3://mdge-e3-2024/parquet_files_partitioned/categoria=material escolar/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f02bad",
   "metadata": {},
   "source": [
    "- ¿Cuańtas marcas diferentes tiene tu categoría?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7e43bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "# Count distinct brands in the category\n",
    "distinct_brands = df_cat.agg(countDistinct(\"marca\").alias(\"distinct_brands\"))\n",
    "distinct_brands.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15babd33",
   "metadata": {},
   "source": [
    "- ¿Cuál es la marca con mayor precio? ¿En qué estado?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4eaf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import max, struct\n",
    "\n",
    "# Find the brand with the highest price and the state\n",
    "brand_highest_price = df_cat.select(\"marca\", \"estado\", \"precio\").groupBy(\"marca\", \"estado\").agg(max(\"precio\").alias(\"max_precio\"))\n",
    "brand_highest_price.orderBy(\"max_precio\", ascending=False).show(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80908e2c",
   "metadata": {},
   "source": [
    "- ¿Cuál es la marca con menor precio en CDMX? (en aquel entonces Distrito Federal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f11de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import min\n",
    "\n",
    "# Filter by CDMX (Distrito Federal) and find the brand with the lowest price\n",
    "brand_lowest_price_cdmx = df_cat.filter(df_cat.estado == \"ciudad de mexico\").groupBy(\"marca\").agg(min(\"precio\").alias(\"min_precio\"))\n",
    "brand_lowest_price_cdmx.orderBy(\"min_precio\", ascending=True).show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f917dc24",
   "metadata": {},
   "source": [
    "- ¿Cuál es la marca con mayores observaciones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c005e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the brand with the most observations\n",
    "brand_most_observations = df_cat.groupBy(\"marca\").count().orderBy(\"count\", ascending=False)\n",
    "brand_most_observations.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239b1cda",
   "metadata": {},
   "source": [
    "- ¿Cuáles son el top 5 de marcas con mayor precio en cada estado? ¿Son diferentes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5de0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the top 5 brands with the highest price in each state\n",
    "top5_brands_per_state = df_cat.groupBy(\"estado\", \"marca\").agg(max(\"precio\").alias(\"max_precio\")).orderBy(\"estado\", \"max_precio\", ascending=[True, False])\n",
    "top5_brands_per_state.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89eab055",
   "metadata": {},
   "source": [
    "- ¿Cuáles son el top 5 de marcas con menor precio en CDMX? (en aquel entonces Distrito Federal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1d8195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by CDMX and find the top 5 brands with the lowest price\n",
    "top5_lowest_price_cdmx = df_cat.filter(df_cat.estado == \"ciudad de mexico\").groupBy(\"marca\").agg(min(\"precio\").alias(\"min_precio\")).orderBy(\"min_precio\", ascending=True).limit(5)\n",
    "top5_lowest_price_cdmx.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e07f665",
   "metadata": {},
   "source": [
    "- ¿Cuáles son el top 5 de marcas con mayores observaciones? ¿Se parecen a las de nivel por estado?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe44b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the top 5 brands with the most observations globally\n",
    "global_top5_observation_brands = df_cat.groupBy(\"marca\").count().orderBy(\"count\", ascending=False).limit(5)\n",
    "global_top5_observation_brands.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d51c4a6",
   "metadata": {},
   "source": [
    "- ¿Ha dejado de existir alguna marca durante los años que tienes? ¿Cuál? ¿Cuándo desapareció?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e452c781",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import min, max\n",
    "\n",
    "# Find if any brand has disappeared over the years\n",
    "# Assuming 'ano' is the year column in your DataFrame\n",
    "brand_years = df_cat.groupBy(\"marca\").agg(min(\"ano\").alias(\"first_year\"), max(\"ano\").alias(\"last_year\"))\n",
    "current_year = df_cat.select(max(\"ano\")).collect()[0][0]  # assuming this retrieves the current or latest year in the dataset\n",
    "disappeared_brands = brand_years.filter(brand_years.last_year < current_year)\n",
    "disappeared_brands.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc4240d",
   "metadata": {},
   "source": [
    "- Genera una gráfica de serie de tiempo por estado para la marca con mayor precio -en todos los años-, donde el eje equis es el año y el eje ye es el precio máximo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adc7712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data for visualization\n",
    "brand_max_price_by_state_year = df_cat.groupBy(\"estado\", \"ano\", \"marca\").agg(max(\"precio\").alias(\"max_precio\")).orderBy(\"estado"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
