{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cec9f1a5",
   "metadata": {},
   "source": [
    "- Carga el CSV en Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf9afcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create or get a Spark session\n",
    "spark = SparkSession.builder.appName(\"Read Compressed CSV from S3\").getOrCreate()\n",
    "\n",
    "# Define the path to your S3 bucket and compressed CSV files\n",
    "s3_bucket_path = \"s3://mdge-e3-2024/*.csv.gz\"\n",
    "\n",
    "# Read the compressed CSV files into a DataFrame\n",
    "df = spark.read.csv(s3_bucket_path, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2558dedb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add \"year\" and \"month\" columns based on \"fecha_registro\"\n",
    "from pyspark.sql import functions as F\n",
    "df = df.withColumn(\"year\", F.year(\"fecha_registro\"))\n",
    "df = df.withColumn(\"month\", F.month(\"fecha_registro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70725b90",
   "metadata": {},
   "source": [
    "- Guarda el CSV como parquet en S3, particionalo por `catalogo`. (Utiliza todos los trucos que consideres)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b221002f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18da3d13261e4cf489405bc9c83a559e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define output directory\n",
    "output_directory = \"s3://mdge-e3-2024/parquet_files_partitioned/\"\n",
    "\n",
    "# Write the DataFrame to Parquet, partitioned by 'categoria', 'year', and 'month'\n",
    "df.write.partitionBy(\"categoria\", \"year\", \"month\").mode('overwrite').parquet(output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d797b7d",
   "metadata": {},
   "source": [
    "- Carga el parquet en Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea1a931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Parquet files into a DataFrame\n",
    "df_parquet = spark.read.parquet(output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c955c32",
   "metadata": {},
   "source": [
    "Contesta las siguientes preguntas utilizando PySpark. Realiza el siguiente análisis **(por año)** y sobre todos los catálogos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a67733d",
   "metadata": {},
   "source": [
    "- ¿Cuántos catálogos diferentes tenemos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f40ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "# Count distinct catalogs\n",
    "distinct_catalogs = df.agg(countDistinct(\"catalogo\").alias(\"distinct_catalogs\"))\n",
    "distinct_catalogs.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e25cb6",
   "metadata": {},
   "source": [
    "- ¿Cuáles son los20 catálogos con más observaciones? Guarda la salida de este query en tu bucket de S3, lo necesitaremos más adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a68eec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "\n",
    "# Find top 20 catalogs by number of observations\n",
    "top_20_catalogs = df.groupBy(\"catalogo\").count().orderBy(desc(\"count\")).limit(20)\n",
    "top_20_catalogs.show()\n",
    "\n",
    "# Save the output to S3\n",
    "top_20_catalogs.write.mode('overwrite').parquet(\"s3://mdge-e3-2024/top_20_catalogs/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52368ced",
   "metadata": {},
   "source": [
    "- ¿Tenemos datos de todos los estados del país? De no ser así, ¿cuáles faltan?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa9adf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_states = [\n",
    "    \"aguascalientes\", \"baja california\", \"baja california sur\", \"campeche\", \"chiapas\",\n",
    "    \"chihuahua\", \"ciudad de mexico\", \"coahuila\", \"colima\", \"durango\", \"guanajuato\",\n",
    "    \"guerrero\", \"hidalgo\", \"jalisco\", \"mexico\", \"michoacan\", \"morelos\", \"nayarit\",\n",
    "    \"nuevo leon\", \"oaxaca\", \"puebla\", \"queretaro\", \"quintana roo\", \"san luis potosi\",\n",
    "    \"sinaloa\", \"sonora\", \"tabasco\", \"tamaulipas\", \"tlaxcala\", \"veracruz\", \"yucatan\", \"zacatecas\"\n",
    "]\n",
    "\n",
    "# Get distinct states from DataFrame\n",
    "states_in_data = df.select(\"estado\").distinct().rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "# Find missing states\n",
    "missing_states = [state for state in all_states if state not in states_in_data]\n",
    "print(\"Missing States:\", missing_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613d59a5",
   "metadata": {},
   "source": [
    "- ¿Cuántas observaciones tenemos por estado?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ee0b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count observations by state\n",
    "observations_by_state = df.groupBy(\"estado\").count()\n",
    "observations_by_state.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b24503",
   "metadata": {},
   "source": [
    "- De cada estado obten: el número de catalogos diferentes por año, ¿ha aumentado el número de catálogos con el tiempo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70c605b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year\n",
    "\n",
    "# Count distinct catalogs per state per year\n",
    "catalogs_per_state_per_year = df.groupBy(\"estado\", \"year\").agg(countDistinct(\"catalogo\").alias(\"distinct_catalogs\"))\n",
    "catalogs_per_state_per_year.show()\n",
    "\n",
    "# To check if the number of catalogs has increased over the years, we will order the results\n",
    "trend_catalogs = catalogs_per_state_per_year.orderBy(\"estado\", \"year\")\n",
    "trend_catalogs.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1088c648",
   "metadata": {},
   "source": [
    "Utilizando Spark contesta las siguientes preguntas a partir **del catálogo que\n",
    "le tocó a tu equipo**. Recuerda trabajar en el archivo con los datos particionados\n",
    "de otra manera tus queries van a tardar mucho."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443f3e0f",
   "metadata": {},
   "source": [
    "- ¿Cuańtas marcas diferentes tiene tu categoría?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e79e73e",
   "metadata": {},
   "source": [
    "- ¿Cuál es la marca con mayor precio? ¿En qué estado?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e116fc21",
   "metadata": {},
   "source": [
    "- ¿Cuál es la marca con menor precio en CDMX? (en aquel entonces Distrito Federal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfa2880",
   "metadata": {},
   "source": [
    "- ¿Cuál es la marca con mayores observaciones?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0ddd4a",
   "metadata": {},
   "source": [
    "- ¿Cuáles son el top 5 de marcas con mayor precio en cada estado? ¿Son diferentes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4ab78f",
   "metadata": {},
   "source": [
    "- ¿Cuáles son el top 5 de marcas con menor precio en CDMX? (en aquel entonces Distrito Federal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd57356",
   "metadata": {},
   "source": [
    "- ¿Cuáles son el top 5 de marcas con mayores observaciones? ¿Se parecen a las de nivel por estado?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fea26c5",
   "metadata": {},
   "source": [
    "- ¿Ha dejado de existir alguna marca durante los años que tienes? ¿Cuál? ¿Cuándo desapareció?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c762f962",
   "metadata": {},
   "source": [
    "- Genera una gráfica de serie de tiempo por estado para la marca con mayor precio -en todos los años-, donde el eje equis es el año y el eje ye es el precio máximo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
